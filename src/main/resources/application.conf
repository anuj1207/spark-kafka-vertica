technohub {
  spark {
    master = "local[*]"
    master = ${?MASTER}
    app.name = "kafka-spark-vertica"
    app.name = ${?APP_NAME}
    log.level = "ERROR"
    log.level = ${?SPARK_LOG_LEVEL}
    checkpoint.location = "src/main/resources/checkpoints"
    checkpoint.location = ${?CHECKPOINTS_PATH}
    trigger.time = 2
    trigger.time = ${?TRIGGER_INTERVAL}
  }

  vertica {
    source {
      dbschema = "db_schema"
      dbschema = ${?DB_SCHEMA_SOURCE}
      table = "vertica_table_source"
      table = ${?DB_TABLE_SOURCE}
      numPartitions = 16 //default value
      numPartitions = ${?VERTICA_NUM_PARTITIONS}
    }
    sink {
      dbschema = "db_schema"
      dbschema = ${?DB_SCHEMA_SINK}
      table = "vertica_table_sink"
      table = ${?DB_TABLE_SINK}
    }
    db = "test"
    db = ${?DB_NAME}
    user = "dbadmin"
    user = ${?DB_USER}
    password = "password"
    password = ${?DB_PASSWORD}
    user_name = "dbadmin"
    host = "localhost"
    host = ${?DB_HOST}
    hdfs_url = "hdfs://localhost:9000/user"
    hdfs_url = ${?HDFS_URL}
    web_hdfs_url = "webhdfs://localhost:50070/user"
    web_hdfs_url = ${?WEB_HDFS_URL}
  }

  kafka {
    broker = "localhost:9092"
    broker = ${?BROKER}
    source {
      topic = "source-topic"
      topic = ${?TOPIC_SOURCE}
      group.id = "group"
      group.id = ${?KAFKA_GROUP}
      earliest = true
      earliest = ${?EARLIEST_OFFSET}
      max.offsets.per.trigger = 1
      max.offsets.per.trigger = ${?TRIGGER_OFFSETS}
    }
    sink {
      topic = "sink-topic"
      topic = ${?TOPIC_SINK}
    }
  }
}
